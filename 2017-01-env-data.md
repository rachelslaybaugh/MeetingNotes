Environmental Knowledgebase Workshop

Jan 21, 2017

UCB, BIDS

Objective: This one day workshop focuses on exploring and linking
Berkeley-based projects, expertise, advances and opportunities that could be
relevant to a future environmental knowledgebase. 


#### <a name="top">Content
1. Introduction
2. [Snapshots Part 1](#snap1)
3. [Data Science Initiative](#ds)
4. [Snapshots Part 2](#snap2)
5. [Computational/Statistics](#stats)
6. [Breakout](#breakout)
7. [Discussion](#discussion)


### <a name="snap1">Snapshots Part 1
* Neil Davies – Moorea Project
  - ecology can work at the scale of the planet; huge amounts of very large
    data.
  - we also care about things at the human scale; all politics is local
  - how do we integrate large-scale changes to local impact?
  - we need to model both global scale _and_ local scale to see how they
    interact with one another. "genome up" and "planet down"
  - roadmap

* Susan Hubbard – Watershed Science (looks like a person I should talk to)
  - how do watersheds respond to perturbations in rainfall, etc.? How do we
    predict that?
  - how do you figure out the resolution needed? 
  - looking to predict aggregate behavior--using AMR and scale-adaptive
    strategy
  - data heterogeneity: multi-scale, multi-resolution
  - very hierarchically-nested measurements
  - wish list: anomaly detection and notification; image analysis
    assimilation; automatic synthesis. This is a good slide...
  - How do we really figure out what data we need to use out of the data we
    collect? How do we do that formally? Perturbation studies? Machine
    learning?
  - This project uses Broker Approach, which sorts through data and pulls out
    what it thinks are important

* Maggi Kelly – Drones & Historical Data
  - 21st century mapping toolkits for large humanitarian questions
  - **This** digitizing historical data, used holos eco engine (open API) to do this
  - **This** also taking old reports, scanning, using Watson Alchemy API, and bringing
    out the main components of those research items
  - they're taking new images and there is still this global / local challenge
  - big challenge in linguistics and text processing for getting out this old
    data
  - Raster Foundry

* Chris Mungall - Ontology Learning for Biosciences, Energy, and the Environment
  - fuse data and knoweldge to enable decision support for env and energy
  - different ontologies for classifying different types of data
    ([geneonotology.org](http://www.geneontology.org/),
     [environmentontology.org](http://www.environmentontology.org))
  - looking at automatically classifying data as it's being generated: combine
    data, databases, and literature information; combined knowledge systems
  - use the question you're asking to guide how much of which inputs you want
  - monarch initiative
  - challenge with standardized formats

[Index](#top)


### <a name="ds">Data Science Initiative -- Michael Jordan
- open source platforms have largely won out; RiseLab is starting (AMP lab in
  the past)
- building these systems correctly is _very_ important; engineering has a
  different impact level than not finding the correct yelp location
- data science courses are in high demand, connector courses are connecting the
  DS courses to domains; targeting having about 20--getting people into those
  disciplines
- new dean is going to oversee this new division (real power); still looking
  for person. 
- **This** graphical models to integrate multi-modal data; they bring probability to
  bear and can help find those connections. Kernel methods are another way to
  help with this; multiple kernel
- machine learning is his field, data integration and inferential issues is
  about half of the people into this (the other half is for managing and
  data-basing the data)
- machine learning is just statistics with a computational bent. Fields should
  never have been separated. It's just probabilistic computation; really
  statistics. CS just reinvented statistics...

[Index](#top)


### <a name="snap2">Snapshots Part 2
* Trevor Keenan- Ameriflux 
  - challenge in temporal frequency; very complex systems. Lots of data--machine
    learning and using it to scale up in space (sporadic in space and time)
  - interesting problems in how to take small bits of data from different
    locations and times to extrapolate--completeness of data issues. How do you
    decide what is a complete data set. 

* Adam Arkin – Kbase
  - "literature is increasing accessible and poorly assessable."
  - automated reasoning about assertions for knowledge engine to evolve
  - communication among scientists beyond pdfs
  - Kbase is a big tool to facilitate science. Are people really adopting this?
    There are some compelling reasons, which is encouraging adoption. Unclear how
    well this is or is going to work. Yay for giant, multi-lab things

* Charles Marshall – Museums
  - ameriflux sensors
  - we're great at collecting data; not so good at figuring out what it means
  - guidance from above + data integration from below

[Index](#top)


### <a name="stats">Computational / Statistics

After I learn more, these are folks for real technical questions

* Francois Belletti
  - remembering what just happened is important for decision making. This seems
    useful, but I sort of spaced for part of it.
  - multiple input control
  - need to go back and learn this part. Missed most of it. Oops. 
  - don't use a neural network if you don't have large amounts of data. 

* Streaming/time series data: Mark VanDer Laan 
  - we often have a problem that the underlying models are completely off, so
    the P value and indicators of validity are completely wrong. 
  - looking for realistic statistical models; targeted learning
  - machine learning uses highly adaptive methods, but doesn't include theory
  - targeted learning brings together causal frameworks, machine learning, and
    statistical theory
  - Targeted Learning: 
    1. Super Learning: fit of stochastic system. Set up competition between
       models and algorithms; judge honestly what performs the best
    2. Targeting: focus on causal questions and update super learning based on
       this part

I need to learn about Machine learning v neural networks v statistical theory v
artificial intelligence. I don't really know what these things mean. 

* Principled assimilation/integration of mechanistic and data driven/statistical
models: George Pau
  - challenges with having enough data and overfitting the data that you have

[Index](#top)


### <a name="breakout">Breakout

Fernando and Susan made some good overview sketches

[Index](#top)


### <a name="discussion">Discussion

[Index](#top)
