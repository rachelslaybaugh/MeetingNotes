Development of Modern Methods for Linear Algebra

UCB

23 October, 2015

### <a name="top">Speakers
1. [Grey Ballard, Sandia](#ballard)
2. [Austin Benson, Standford](#benson)
3. [Erin Carson, NYU](#carson)
4. [Greg Henry, Intel](#henry)
5. [Jeff Bilmes, UW](#bilmes)
6. [David Garmire, U Hawaii](#garmire-d)
7. [Lana Garmire, U Hawaii](#garmire-l)
8. [Tzu-Yi Chen, Pomona](#chen)
9. [Ken Stanley, Du Bois Project of Oberlin](#stanley)

#### <a name="ballard"> Parallel Tensor Compression for Large-Scale Scientific Dat

- was not taking notes yet, but this looked super interesting
- get slides

[Speaker List](#top)



#### <a name="benson"> Network clustering with higher-order structures

- Two fundamental graph analyses: real-world networks have modular organizeaiton, 
- unifies themes and uses clustering for higher order information
- motif-based clustering by generalizing spectral clustering
- conductance -> spectral clustering -> pretty clear slides
- I don't think about graphs much, so I'm not too familiar with any of this stuff.

[Speaker List](#top)



#### <a name="carson"> Communication-Avoiding Krylov Methods in Theory and Practice

- algos have 2 costs: communication and computation. Moving data is between levels of memory hierarchy and processors
- over time, memory and interconnect latency and interconnect bandwidth are not improving: barriers to exascale
- Krylov subspace methods
- communication: add dimension to K_m is a sparse mat-vec mult, parallel: comm vec entries w neighbors; orthogonalize requires inner products, in parallel global reduce 
- get slides for this, could be useful
- went thru how this maps to cg
- ideaL compute blocks of s iterations at once to reduce communication cost by O(s) - idea that has been frequently rediscovered
- resurgence of interest in recent years b/c of prob size and comm cost
- basically moving work from message passing to flops and words moved - so can be a win depending on machine
- can auto-tune to find the best s (degree of unrolling)
- however, s will also impact convergence rate and accuracy
- theoretically the same (Krylov and comm-avoiding Krylov); issue with finite precision
- can get a bound
- use residual replacement strategy (update with true), but only do it sometimes
- use Paige's Lanczos convergence analysis as a starting point for their convergence analysis
- also look at work by Greenbaum to look at eigenvalue precision.
- may be promising...could be something to look into? Maybe it would fix my mg method? That thing is soooo sloooow

[Speaker List](#top)



#### <a name="henry"> Software Design for Small Matrices

- idea of setting a flag to do JIT optimization for really small things that you do a whole bunch of times
- based loosely on libxsmm, which is currently on github
- (also mlk_direct_call)
- the compiler can't beat a really smart person writing assembly. 
- this is for small mat-mat mult
- there are two other options besides compiler flag: manually get routines for best performance or utilities that create static kernels for the user

[Speaker List](#top)



#### <a name="bilmes"> A PHiPAC Retrospective

[Speaker List](#top)



#### <a name="garmire-d"> Application of Linear Algebra to Making

[Speaker List](#top)



#### <a name="garmire-l	"> Integration of Big Data in Cancer Research

[Speaker List](#top)




#### <a name="chen"> On communities: algorithms, experiments, and experiences

[Speaker List](#top)



#### <a name="stanley"> Making math fun for math-phobic children

[Speaker List](#top)
